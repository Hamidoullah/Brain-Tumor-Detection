{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e92c97-34da-42dc-b94d-de4085c31f73",
   "metadata": {},
   "source": [
    "Installer des versions spécifiques de tensorflow (2.14.0) et keras (2.14.0) pour garantir leur compatibilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518612e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.14.0\n",
    "!pip install keras==2.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77beb7-d987-4a42-aa44-06ecd1ee284f",
   "metadata": {},
   "source": [
    "Afficher la version de tensorflow installée en important la bibliothèque et en imprimant sa version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff109ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tensorflow.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc2f3dc-9dc0-4e23-9a7d-95a0ed61d7b1",
   "metadata": {},
   "source": [
    "Importer les bibliothèques nécessaires pour manipuler les fichiers, effectuer des calculs numériques, créer et entraîner des réseaux de neurones, gérer des ensembles de données, transformer des images, et afficher une barre de progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9902bbb-00a0-452a-9739-1df4d4eed688",
   "metadata": {},
   "source": [
    "La fonction load_images permet Charger des images à partir d'un dossier donné, les redimensionne, et les normalise entre -1 et 1, avant de les retourner sous forme de liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bd47b-1338-4ff4-80a8-6c44886fa0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Fonction de chargement des images -----------\n",
    "def load_images(data_path, img_shape):\n",
    "    images = []\n",
    "    for img_name in os.listdir(data_path):\n",
    "        img_path = os.path.join(data_path, img_name)\n",
    "        img = load_img(img_path, target_size=img_shape)\n",
    "        img = img_to_array(img) / 127.5 - 1  # Normalisation entre -1 et 1\n",
    "        images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d3425-d19e-4dd6-8315-7b95bf657d04",
   "metadata": {},
   "source": [
    "Définir un générateur de réseau de neurones pour créer des images à partir d'un vecteur latent, en utilisant des couches entièrement connectées et transposées convolutives, suivi de normalisations et d'activations pour produire une image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f8514-91c6-4550-a055-0d4edf9f6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Générateur -----------\n",
    "def build_generator(latent_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128 * 32 * 32, activation=\"relu\", input_dim=latent_dim),\n",
    "        layers.Reshape((32, 32, 128)),\n",
    "        layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding=\"same\", activation=\"tanh\"),\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4897c11-e36e-417f-af89-17ac23000667",
   "metadata": {},
   "source": [
    "Définir un discriminateur, un réseau de neurones convolutif conçu pour différencier les images réelles des images générées, en utilisant des couches convolutives, des normalisations, des activations et une sortie sigmoïde pour produire une probabilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6672a-f316-4211-9af0-ab0a9974f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Discriminateur -----------\n",
    "def build_discriminator(img_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\", input_shape=img_shape),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2D(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc74c2-0151-432a-9a1b-4e975123b7ce",
   "metadata": {},
   "source": [
    "Initialiser les paramètres du modèle et les hyperparamètres : dimension du vecteur latent (100), taille des images (128x128), chemin des données, taille de batch (64), nombre d'époques (2000), et taux d'apprentissage (0.0002)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde68e4d-a48f-47ae-84c9-dfb3b911ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Hyperparamètres -----------\n",
    "latent_dim = 100\n",
    "img_shape = (128, 128, 3)\n",
    "data_path = \"Dataset/tumor\"\n",
    "batch_size = 64\n",
    "num_epochs = 2000\n",
    "lr = 0.0002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402607f9-c9f3-406c-8ef0-85148532a8c6",
   "metadata": {},
   "source": [
    "Charger les données avec un DataLoader, crée les modèles de générateur et de discriminateur, initialise les optimiseurs avec l'algorithme Adam et définit la fonction de perte (BinaryCrossentropy) pour l'entraînement du GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1780ed4-6166-4110-9bb8-270218087330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "images = load_images(data_path, img_shape[:2])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(images).batch(batch_size).shuffle(buffer_size=1024)\n",
    "\n",
    "# Créer les modèles\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator(img_shape)\n",
    "\n",
    "# Optimiseurs\n",
    "optimizer_G = Adam(lr, beta_1=0.5)\n",
    "optimizer_D = Adam(lr, beta_1=0.5)\n",
    "\n",
    "# Fonction de perte\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e9a4b-9404-4219-8ab4-aa7c2f75f2ff",
   "metadata": {},
   "source": [
    "Entraîner un GAN pendant 2000 époques en optimisant le générateur et le discriminateur. À chaque époque, le générateur crée de fausses images et le discriminateur apprend à distinguer les vraies des fausses. Les pertes des deux modèles sont calculées et les paramètres sont mis à jour. Toutes les 100 époques, des images générées sont sauvegardées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dabba9f-0028-485a-8cb4-086df123e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Entraînement -----------\n",
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "    valid = tf.ones((batch_size, 1))\n",
    "    fake = tf.zeros((batch_size, 1))\n",
    "    \n",
    "    # Entraîner le générateur\n",
    "    with tf.GradientTape() as tape:\n",
    "        z = tf.random.normal((batch_size, latent_dim))\n",
    "        generated_images = generator(z, training=True)\n",
    "        g_loss = loss_fn(valid, discriminator(generated_images, training=True))\n",
    "    gradients_g = tape.gradient(g_loss, generator.trainable_variables)\n",
    "    optimizer_G.apply_gradients(zip(gradients_g, generator.trainable_variables))\n",
    "    \n",
    "    # Entraîner le discriminateur\n",
    "    with tf.GradientTape() as tape:\n",
    "        real_loss = loss_fn(valid, discriminator(real_images, training=True))\n",
    "        fake_loss = loss_fn(fake, discriminator(generated_images, training=True))\n",
    "        d_loss = 0.5 * (real_loss + fake_loss)\n",
    "    gradients_d = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    optimizer_D.apply_gradients(zip(gradients_d, discriminator.trainable_variables))\n",
    "    \n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a97b13e-633f-4daf-8f9d-b8a15b4c2955",
   "metadata": {},
   "source": [
    "Entraîner un GAN pendant 2000 époques en optimisant le générateur et le discriminateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle d'entraînement\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training GAN\"):\n",
    "# for epoch in range(num_epochs):\n",
    "    for real_images in dataset:\n",
    "        d_loss, g_loss = train_step(real_images)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} | D Loss: {d_loss:.4f} | G Loss: {g_loss:.4f}\")\n",
    "    \n",
    "    # Sauvegarde des images toutes les 100 époques\n",
    "    if epoch % 100 == 0:\n",
    "        z = tf.random.normal((16, latent_dim))\n",
    "        generated_images = generator(z, training=False)\n",
    "        for idx, img in enumerate(generated_images):\n",
    "            img = (img + 1) / 2.0  # Re-normaliser entre 0 et 1 pour sauvegarde\n",
    "            tf.keras.preprocessing.image.save_img(f\"keras_generated_image_epoch_{epoch}_img_{idx}.png\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793f75b-2c87-4521-94e2-0431c5a6bfea",
   "metadata": {},
   "source": [
    "Génèrer 16 images après l'entraînement à partir de vecteurs aléatoires en utilisant le générateur, et les sauvegarde sous forme de fichiers .png, avec un nom de fichier qui inclut l'index de l'image. Les images sont générées sans calcul de gradients pour économiser de la mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f547ffc2-bf1e-48de-b534-98276c72902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Générer des images après l'entraînement -----------\n",
    "z = tf.random.normal((16, latent_dim))\n",
    "generated_images = generator(z, training=False)\n",
    "for idx, img in enumerate(generated_images):\n",
    "    img = (img + 1) / 2.0  # Re-normaliser entre 0 et 1 pour sauvegarde\n",
    "    tf.keras.preprocessing.image.save_img(f\"keras_final_generated_image_{idx}.png\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80db18-6c3b-4209-be45-b403ac7d661d",
   "metadata": {},
   "source": [
    "Sauvegarder les poids du modèle du générateur et du discriminateur dans des fichiers .keras afin de pouvoir les recharger et les réutiliser plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le générateur et le discriminateur après l'entraînement\n",
    "generator.save(\"generator_model.keras\")\n",
    "discriminator.save(\"discriminator_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139ac45-7e34-4511-b1c5-826cfb974fee",
   "metadata": {},
   "source": [
    "Charger les modèles préalablement sauvegardés en réinitialisant les instances du générateur et du discriminateur, puis charge les poids des modèles sauvegardés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a8e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Charger le générateur et le discriminateur\n",
    "generator = load_model(\"generator_model.keras\")\n",
    "discriminator = load_model(\"discriminator_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98edeeae-b684-4608-9578-eccd10f01c2c",
   "metadata": {},
   "source": [
    "Génèrer 16 images à partir de vecteurs aléatoires en utilisant le générateur, et les sauvegarde sous forme de fichiers .png, avec un nom de fichier qui inclut l'index de l'image. Les images sont générées sans calcul de gradients pour économiser de la mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05be6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer des images en utilisant le générateur chargé\n",
    "z = tf.random.normal((16, latent_dim))  # latent_dim doit correspondre à la dimension utilisée à l'entraînement\n",
    "generated_images = generator(z)\n",
    "\n",
    "# Sauvegarder les images générées\n",
    "for idx, img in enumerate(generated_images):\n",
    "    img = (img + 1) / 2.0  # Re-normaliser entre 0 et 1 pour sauvegarde\n",
    "    tf.keras.preprocessing.image.save_img(f\"loaded_model_generated_image_{idx}.png\", img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
